{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - MURA-Finance Project\n",
    "**Phase 1, Task 1: Data Exploration**\n",
    "\n",
    "This notebook performs comprehensive data exploration on all CSV files.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect all CSV files\n",
    "2. Understand data schema and column meanings\n",
    "3. Check data quality (missing values, duplicates)\n",
    "4. Analyze data distributions (sentiment, ticker, temporal)\n",
    "5. Map relationship between ground truth and predictions\n",
    "6. Identify data inconsistencies or anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from src.utils.data_loader import (\n",
    "    load_all_dataframes,\n",
    "    get_schema_info,\n",
    "    print_dataframe_summary,\n",
    ")\n",
    "from src.utils.analysis import (\n",
    "    analyze_sentiment_distribution,\n",
    "    map_ground_truth_to_predictions,\n",
    ")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base path\n",
    "base_path = Path().resolve().parent\n",
    "\n",
    "# Load all dataframes\n",
    "print(\"Loading dataframes...\")\n",
    "data = load_all_dataframes(base_path)\n",
    "\n",
    "print(f\"\\nLoaded {len(data)} data files\\n\")\n",
    "\n",
    "# Display what we loaded\n",
    "for name, df in data.items():\n",
    "    print(f\"{name}: {len(df)} rows × {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ground Truth Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ground_truth\" in data:\n",
    "    df_gt = data[\"ground_truth\"]\n",
    "\n",
    "    print_dataframe_summary(df_gt, \"Ground Truth\")\n",
    "\n",
    "    # Display schema\n",
    "    schema_info = get_schema_info(df_gt, \"Ground Truth\")\n",
    "    display(schema_info)\n",
    "\n",
    "    # Show first few rows\n",
    "    display(df_gt.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution with visualization\n",
    "if \"ground_truth\" in data and \"true_sentiment\" in data[\"ground_truth\"].columns:\n",
    "    df_gt = data[\"ground_truth\"]\n",
    "\n",
    "    sentiment_dist = analyze_sentiment_distribution(df_gt, \"true_sentiment\")\n",
    "\n",
    "    print(\"Sentiment Distribution:\")\n",
    "    for sentiment, count in sentiment_dist[\"counts\"].items():\n",
    "        pct = sentiment_dist[\"percentages\"].get(sentiment, 0)\n",
    "        print(f\"  {sentiment}: {count} ({pct}%)\")\n",
    "\n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Bar chart\n",
    "    sentiment_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Sentiment\": list(sentiment_dist[\"counts\"].keys()),\n",
    "            \"Count\": list(sentiment_dist[\"counts\"].values()),\n",
    "        }\n",
    "    )\n",
    "    sns.barplot(data=sentiment_df, x=\"Sentiment\", y=\"Count\", ax=ax1)\n",
    "    ax1.set_title(\"Sentiment Distribution - Counts\")\n",
    "    ax1.set_ylabel(\"Count\")\n",
    "\n",
    "    # Pie chart\n",
    "    ax2.pie(\n",
    "        sentiment_dist[\"counts\"].values(),\n",
    "        labels=sentiment_dist[\"counts\"].keys(),\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "    )\n",
    "    ax2.set_title(\"Sentiment Distribution - Percentages\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single Article Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"single_article\" in data:\n",
    "    df_single = data[\"single_article\"]\n",
    "\n",
    "    print(f\"Shape: {df_single.shape[0]} rows × {df_single.shape[1]} columns\")\n",
    "\n",
    "    # Analyze sentiment columns\n",
    "    sentiment_cols = [col for col in df_single.columns if \"sentiment\" in col.lower()]\n",
    "    print(f\"\\nFound {len(sentiment_cols)} sentiment columns:\")\n",
    "    for col in sentiment_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "    # Show schema for first 20 columns\n",
    "    schema_info = get_schema_info(df_single, \"Single Article\")\n",
    "    display(schema_info.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ground Truth vs Predictions Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ground_truth\" in data and \"single_article\" in data:\n",
    "    merged, mapping_stats = map_ground_truth_to_predictions(\n",
    "        data[\"ground_truth\"], data[\"single_article\"]\n",
    "    )\n",
    "\n",
    "    print(\"Mapping Statistics:\")\n",
    "    print(f\"  Ground truth records: {mapping_stats['total_ground_truth']}\")\n",
    "    print(f\"  Prediction records: {mapping_stats['total_predictions']}\")\n",
    "    print(f\"  Matched records: {mapping_stats['matched_records']}\")\n",
    "    print(f\"  Match rate: {mapping_stats['match_rate']}%\")\n",
    "\n",
    "    if mapping_stats[\"matched_records\"] > 0:\n",
    "        print(\"\\n✓ Ground truth and predictions can be matched!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Inconsistencies & Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sentiment encoding mismatch\n",
    "if \"ground_truth\" in data and \"single_article\" in data:\n",
    "    df_gt = data[\"ground_truth\"]\n",
    "    df_single = data[\"single_article\"]\n",
    "\n",
    "    if \"true_sentiment\" in df_gt.columns and \"true_sentiment\" in df_single.columns:\n",
    "        gt_unique = set(df_gt[\"true_sentiment\"].unique())\n",
    "        single_unique = set(df_single[\"true_sentiment\"].unique())\n",
    "\n",
    "        print(\"⚠ Sentiment Encoding Mismatch:\")\n",
    "        print(f\"  Ground Truth: {gt_unique}\")\n",
    "        print(f\"  Predictions: {single_unique}\")\n",
    "        print(\"\\n  Mapping needed:\")\n",
    "        print(\"    Positive ↔ 1\")\n",
    "        print(\"    Neutral ↔ 0\")\n",
    "        print(\"    Negative ↔ -1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
